# ğŸ›¡ï¸ Auto Bug Detection using Graph Transformer

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/PyTorch-2.1+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch">
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License">
  <img src="https://img.shields.io/badge/Status-Academic%20Project-blue?style=for-the-badge" alt="Status">
</p>

<p align="center">
  <strong>Äá»“ Ã¡n mÃ´n há»c: PhÃ¡t hiá»‡n lá»— há»•ng báº£o máº­t tá»± Ä‘á»™ng trong mÃ£ nguá»“n C/C++ sá»­ dá»¥ng Graph Transformer</strong>
</p>

---

## ğŸ“‹ Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng **phÃ¡t hiá»‡n lá»— há»•ng báº£o máº­t tá»± Ä‘á»™ng** trong mÃ£ nguá»“n C/C++ sá»­ dá»¥ng mÃ´ hÃ¬nh **Graph Transformer**. Há»‡ thá»‘ng há»c biá»ƒu diá»…n tá»« hai view Ä‘á»“ thá»‹:

| View | MÃ´ táº£ |
|------|-------|
| **AST** (Abstract Syntax Tree) | CÃ¢y cÃº phÃ¡p trá»«u tÆ°á»£ng - biá»ƒu diá»…n cáº¥u trÃºc ngá»¯ phÃ¡p cá»§a mÃ£ nguá»“n |
| **CDFG** (Control Data Flow Graph) | Äá»“ thá»‹ luá»“ng Ä‘iá»u khiá»ƒn vÃ  dá»¯ liá»‡u - biá»ƒu diá»…n luá»“ng thá»±c thi vÃ  phá»¥ thuá»™c dá»¯ liá»‡u |

### ğŸ¯ Má»¥c tiÃªu

- PhÃ¡t hiá»‡n cÃ¡c lá»— há»•ng báº£o máº­t phá»• biáº¿n (CWE-77, Command Injection, Buffer Overflow...)
- á»¨ng dá»¥ng Deep Learning (Graph Neural Networks) vÃ o bÃ i toÃ¡n phÃ¢n tÃ­ch mÃ£ nguá»“n
- Káº¿t há»£p thÃ´ng tin tá»« nhiá»u biá»ƒu diá»…n Ä‘á»“ thá»‹ Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c

---

## ğŸ—ï¸ Kiáº¿n trÃºc Model

```
                    +---------------------------+
                    |   Input: Source Code      |
                    |        (C/C++)            |
                    +-------------+-------------+
                                  |
                    +-------------+-------------+
                    |                           |
                    v                           v
            +-------+-------+           +-------+-------+
            |      AST      |           |     CDFG      |
            |     Graph     |           |     Graph     |
            +-------+-------+           +-------+-------+
                    |                           |
                    v                           v
            +-------+-------+           +-------+-------+
            | Node Feature  |           | Node Feature  |
            | Encoder (MLP) |           | Encoder (MLP) |
            +-------+-------+           +-------+-------+
                    |                           |
                    v                           v
            +-------+-------+           +-------+-------+
            |    Graph      |           |    Graph      |
            |  Transformer  |           |  Transformer  |
            |  (4 layers)   |           |  (4 layers)   |
            | - Multi-head  |           | - Multi-head  |
            |   Attention   |           |   Attention   |
            | - Edge Bias   |           | - Edge Bias   |
            | - FFN + LN    |           | - FFN + LN    |
            +-------+-------+           +-------+-------+
                    |                           |
                    v                           v
            +-------+-------+           +-------+-------+
            | Weighted Sum  |           | Weighted Sum  |
            | Readout Layer |           | Readout Layer |
            +-------+-------+           +-------+-------+
                    |                           |
                    +-------------+-------------+
                                  |
                                  v
                    +-------------+-------------+
                    |         Concat            |
                    |      [AST + CDFG]         |
                    +-------------+-------------+
                                  |
                                  v
                    +-------------+-------------+
                    |        Classifier         |
                    |          (MLP)            |
                    +-------------+-------------+
                                  |
                                  v
                    +-------------+-------------+
                    |         Output:           |
                    |   Vulnerable / Safe       |
                    +---------------------------+
```

---

## ğŸ“ Cáº¥u trÃºc Project

```
Auto_Bug_Detection/
|-- Train_Model.py          # Script huan luyen model
|-- Detector.py             # Script phat hien lo hong
|-- Code2Graph.py           # Chuyen doi code thanh graph
|-- Requirements.txt        # Dependencies
|-- README.md               # Documentation
|-- .gitignore              # Git ignore rules
|
|-- TIFS_Data/              # Dataset (tai tu Drive)
|   |-- SARD/               # Raw SARD dataset
|   |-- SARD_after/         # Preprocessed data
|   |-- graphs/             # Generated graphs
|   +-- preprocess_sard.py  # Preprocessing script
|
|-- Trained_Model/          # Model checkpoints
|   |-- Auto_Bug_Detector.pt
|   +-- Auto_Bug_Detector_best.pt
|
|-- logs/                   # Training logs (TensorBoard)
|
+-- evaluation_results/     # Evaluation metrics
```

---

## ğŸ“¥ Dataset

> âš ï¸ **LÆ°u Ã½:** Folder `TIFS_Data/` chá»©a dataset SARD ráº¥t náº·ng (~2GB+) nÃªn **khÃ´ng Ä‘Æ°á»£c commit lÃªn Git**.

### Táº£i Dataset

ğŸ“¦ **Google Drive:** [Click Ä‘á»ƒ táº£i TIFS_Data](https://drive.google.com/drive/folders/YOUR_FOLDER_ID_HERE?usp=sharing)

Sau khi táº£i vá»:
1. Giáº£i nÃ©n file (náº¿u lÃ  .zip)
2. Äáº·t folder `TIFS_Data/` vÃ o thÆ° má»¥c gá»‘c cá»§a project
3. Cáº¥u trÃºc Ä‘Ãºng: `Auto_Bug_Detection/TIFS_Data/SARD/...`

### Dataset Info

| ThÃ´ng tin | GiÃ¡ trá»‹ |
|-----------|---------|
| **Nguá»“n** | SARD (Software Assurance Reference Dataset) |
| **NgÃ´n ngá»¯** | C/C++ |
| **Loáº¡i lá»— há»•ng** | CWE-77 (Command Injection), CWE-119 (Buffer Overflow)... |
| **Sá»‘ máº«u** | ~10,000+ functions |
| **Format** | Source code â†’ AST/CDFG graphs â†’ JSONL |

---

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone repository

```bash
git clone https://github.com/X181125/Auto_Bug_Detection.git
cd Auto_Bug_Detection
```

### 2. Táº¡o virtual environment (khuyáº¿n nghá»‹)

```bash
python -m venv venv

# Windows
.\venv\Scripts\activate

# Linux/macOS
source venv/bin/activate
```

### 3. CÃ i Ä‘áº·t dependencies

```bash
pip install -r Requirements.txt
```

### 4. Táº£i dataset

Táº£i `TIFS_Data/` tá»« Google Drive (link á»Ÿ trÃªn) vÃ  Ä‘áº·t vÃ o thÆ° má»¥c project.

---

## ğŸ‹ï¸ Huáº¥n luyá»‡n Model

### Quick Start

```bash
python Train_Model.py
```

### Vá»›i Custom Parameters

```bash
python Train_Model.py \
    --epochs 50 \
    --lr 1e-3 \
    --state-dim 128 \
    --num-layers 4 \
    --num-heads 4 \
    --patience 10
```

### Training Arguments

| Argument | Default | MÃ´ táº£ |
|----------|---------|-------|
| `--epochs` | `50` | Sá»‘ epochs huáº¥n luyá»‡n |
| `--lr` | `1e-3` | Learning rate |
| `--weight-decay` | `1e-4` | Weight decay (L2 regularization) |
| `--state-dim` | `128` | Hidden dimension |
| `--num-layers` | `4` | Sá»‘ Graph Transformer layers |
| `--num-heads` | `4` | Sá»‘ attention heads |
| `--max-nodes-per-batch` | `8000` | Max nodes má»—i batch |
| `--patience` | `10` | Early stopping patience |

### Theo dÃµi Training vá»›i TensorBoard

```bash
tensorboard --logdir logs
```

---

## ğŸ” PhÃ¡t hiá»‡n Lá»— há»•ng (Inference)

### Sá»­ dá»¥ng file code máº«u

```bash
python Detector.py --source badExample.c
```

### Output máº«u

```
ğŸ“Š Vulnerability Detection Result
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
File: badExample.c
Prediction: âš ï¸ VULNERABLE
Confidence: 87.3%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ“Š Káº¿t quáº£ Thá»±c nghiá»‡m

| Metric | CWE-77 Dataset |
|--------|----------------|
| **Accuracy** | 85-90% |
| **Precision** | 80-85% |
| **Recall** | 80-90% |
| **F1-Score** | 80-87% |

*Káº¿t quáº£ cÃ³ thá»ƒ thay Ä‘á»•i tÃ¹y thuá»™c vÃ o hyperparameters vÃ  quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u.*

---

## ğŸ”§ CÃ¡c thÃ nh pháº§n chÃ­nh

### 1. `Code2Graph.py`
Chuyá»ƒn Ä‘á»•i mÃ£ nguá»“n C/C++ thÃ nh Ä‘á»“ thá»‹ AST vÃ  CDFG.

### 2. `Train_Model.py`
- `GraphTransformerLayer`: Multi-head self-attention vá»›i edge-type embedding
- `GraphTransformerEncoder`: Stack cá»§a N GraphTransformerLayer
- `WeightedSumReadout`: Attention-based pooling
- `VulnDetectorGraphTransformer`: Model chÃ­nh káº¿t há»£p 2 view

### 3. `Detector.py`
Script inference Ä‘á»ƒ phÃ¡t hiá»‡n lá»— há»•ng tá»« file mÃ£ nguá»“n.

---

## âš™ï¸ Hyperparameter Tuning

### Dataset nhá» (< 1000 samples)
```bash
--state-dim 64 --num-layers 2 --num-heads 2 --epochs 30
```

### Dataset vá»«a (1000-10000 samples)
```bash
--state-dim 128 --num-layers 4 --num-heads 4 --epochs 50
```

### Dataset lá»›n (> 10000 samples)
```bash
--state-dim 256 --num-layers 6 --num-heads 8 --epochs 100
```

---

## ğŸ› Troubleshooting

| Váº¥n Ä‘á» | Giáº£i phÃ¡p |
|--------|-----------|
| **Out of Memory** | Giáº£m `--max-nodes-per-batch`, `--state-dim`, `--num-layers` |
| **Overfitting** | TÄƒng `--weight-decay`, giáº£m `--epochs` |
| **Underfitting** | TÄƒng `--state-dim`, `--num-layers`, `--epochs` |
| **Dataset khÃ´ng tÃ¬m tháº¥y** | Kiá»ƒm tra Ä‘Ã£ táº£i `TIFS_Data/` tá»« Drive chÆ°a |

---

## ğŸ“š Tham kháº£o

1. **Graph Transformer Networks** - Yun et al., NeurIPS 2019
2. **Devign: Effective Vulnerability Identification** - Zhou et al., NeurIPS 2019
3. **FUNDED: Flow-based Vulnerability Detection** - Wang et al., ICSE 2020
4. **SARD Dataset** - NIST Software Assurance Reference Dataset

---

## ğŸ‘¨â€ğŸ’» ThÃ´ng tin Äá»“ Ã¡n

| ThÃ´ng tin | Chi tiáº¿t |
|-----------|----------|
| **MÃ´n há»c** | An toÃ n ThÃ´ng tin / Machine Learning |
| **TrÆ°á»ng** | Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin - ÄHQG TPHCM (UIT) |
| **Sinh viÃªn** | Nguyá»…n ÄÃ¬nh HÆ°ng |
| **MSSV** | 23520564 |

---

## ğŸ“„ License

MIT License - Sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u.

---

<p align="center">
  <strong>â­ Náº¿u project há»¯u Ã­ch, hÃ£y cho má»™t star nhÃ©!</strong>
</p>
#   A u t o _ B u g _ D e t e c t i o n 
 
 